global:
  d_model: 512
  d_rout: 1024
  d_rxnout: 27
  
r_enc:
  _target_: synsplore.model.blocks.mlp._SimpleMLP
  d_in: 1024
  d_hidden: 512
  d_out: ${global.d_model}
  n_layers: 3
  h_act: "relu"
  out_act: "none"
  loss: "none"

rxn_enc:
  _target_: "synsplore.model.blocks.utils._SimpleEmbedding"
  n_emb: 100
  d_emb: ${global.d_model}

pos_enc:
  _target_: "synsplore.model.blocks.utils._PositionalEncoding"
  d_model: ${global.d_model}
  dropout: 0.1
  max_len: 1000

seq_enc:
  _target_: "synsplore.model.blocks.tfmer._TransformerDecoder"
  d_model: ${global.d_model}
  n_heads: 8
  n_layers: 6
  d_feedforward: 2048
  output_norm: True
  has_encoder: False

classifier:
  _target_: "synsplore.model.blocks.mlp._SimpleMLP"
  d_in: ${global.d_model}
  d_hidden: 512
  d_out: 4
  n_layers: 3
  h_act: "relu"
  out_act: "none"
  loss: "ce"

r_dec:
  _target_: "synsplore.model.blocks.vae._SimpleVAEDecoder"
  d_in: ${global.d_model}
  d_latent: ${global.d_model} # TOFO
  d_hidden: 512
  d_out: ${global.d_rout}
  n_layers: 3
  h_act: "relu"
  out_act: "none"
  loss: "bce_logits"
  loss_beta: 1

rxn_dec:
  _target_: "synsplore.model.blocks.vae._SimpleVAEDecoder"
  d_in: ${global.d_model}
  d_latent: ${global.d_model} # TOFO
  d_hidden: 512
  d_out: ${global.d_rxnout}
  n_layers: 3
  h_act: "relu"
  out_act: "none"
  loss: "ce"
  loss_beta: 1



